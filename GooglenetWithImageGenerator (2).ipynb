{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "developmental-photograph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15338015631132111906\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15134713447\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17889367360850721277\n",
      "physical_device_desc: \"device: 0, name: Quadro RTX 5000, pci bus id: 0000:65:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "smoking-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "isolated-travel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train_df: 5911\n",
      "Found 5320 validated image filenames belonging to 50 classes.\n",
      "Found 591 validated image filenames belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "print(\"size of train_df:\", len(train_df))\n",
    "\n",
    "# 데이터 노이즈 수정\n",
    "train_df.loc[train_df['id'] == 3896, 'artist'] = 'Titian'\n",
    "train_df.loc[train_df['id'] == 3986, 'artist'] = 'Alfred Sisley'\n",
    "\n",
    "DATAGEN_TRAIN = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    data_format=\"channels_last\",\n",
    "    validation_split=0.10\n",
    ") # Train / Validation\n",
    "\n",
    "TRAIN_GENERATOR = DATAGEN_TRAIN.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='img_path',\n",
    "    y_col='artist',\n",
    "    target_size=(244, 244),\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "VALID_GENERATOR = DATAGEN_TRAIN.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='img_path',\n",
    "    y_col='artist',\n",
    "    target_size=(244, 244),\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "included-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 모델 로드\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(244, 244, 3), pooling=None, input_tensor=None)\n",
    "\n",
    "# 새로운 Fully Connected Layer 추가\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.2)(x) # 드롭아웃 추가\n",
    "predictions = Dense(50, activation='softmax')(x)\n",
    "\n",
    "#전체 모델 구성\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=Adam(lr=3e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "constitutional-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "CP = ModelCheckpoint(filepath='googlenet_model/' + 'GOOGLENET-Sigmoid-{epoch:03d}-{accuracy:.4f}-{val_loss:.4f}.hdf5',\n",
    "                     monitor='val_loss', verbose=1, save_best_only=True, mode='min'\n",
    ")\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1, min_lr=0.00005)\n",
    "CALLBACK = [CP, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "directed-realtor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 167 steps, validate for 19 steps\n",
      "Epoch 1/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 3.1195 - accuracy: 0.2621\n",
      "Epoch 00001: val_loss improved from inf to 3.23453, saving model to googlenet_model/GOOGLENET-Sigmoid-001-0.2628-3.2345.hdf5\n",
      "167/167 [==============================] - 131s 783ms/step - loss: 3.1165 - accuracy: 0.2628 - val_loss: 3.2345 - val_accuracy: 0.2250\n",
      "Epoch 2/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 1.8787 - accuracy: 0.4955\n",
      "Epoch 00002: val_loss did not improve from 3.23453\n",
      "167/167 [==============================] - 113s 677ms/step - loss: 1.8798 - accuracy: 0.4957 - val_loss: 7.1929 - val_accuracy: 0.2995\n",
      "Epoch 3/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 1.3795 - accuracy: 0.6097\n",
      "Epoch 00003: val_loss did not improve from 3.23453\n",
      "167/167 [==============================] - 113s 678ms/step - loss: 1.3779 - accuracy: 0.6102 - val_loss: 3.2855 - val_accuracy: 0.3469\n",
      "Epoch 4/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 1.1051 - accuracy: 0.6711\n",
      "Epoch 00004: val_loss improved from 3.23453 to 2.29246, saving model to googlenet_model/GOOGLENET-Sigmoid-004-0.6720-2.2925.hdf5\n",
      "167/167 [==============================] - 114s 682ms/step - loss: 1.1032 - accuracy: 0.6720 - val_loss: 2.2925 - val_accuracy: 0.4585\n",
      "Epoch 5/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.9318 - accuracy: 0.7184\n",
      "Epoch 00005: val_loss did not improve from 2.29246\n",
      "167/167 [==============================] - 114s 682ms/step - loss: 0.9320 - accuracy: 0.7179 - val_loss: 3.4800 - val_accuracy: 0.4213\n",
      "Epoch 6/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.7760 - accuracy: 0.7672 - ETA:\n",
      "Epoch 00006: val_loss improved from 2.29246 to 1.88361, saving model to googlenet_model/GOOGLENET-Sigmoid-006-0.7671-1.8836.hdf5\n",
      "167/167 [==============================] - 114s 685ms/step - loss: 0.7766 - accuracy: 0.7671 - val_loss: 1.8836 - val_accuracy: 0.5516\n",
      "Epoch 7/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.6629 - accuracy: 0.7982\n",
      "Epoch 00007: val_loss did not improve from 1.88361\n",
      "167/167 [==============================] - 114s 684ms/step - loss: 0.6612 - accuracy: 0.7989 - val_loss: 2.5779 - val_accuracy: 0.5025\n",
      "Epoch 8/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.5919 - accuracy: 0.8183\n",
      "Epoch 00008: val_loss did not improve from 1.88361\n",
      "167/167 [==============================] - 113s 677ms/step - loss: 0.5939 - accuracy: 0.8180 - val_loss: 2.6132 - val_accuracy: 0.4399\n",
      "Epoch 9/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.4950 - accuracy: 0.8432\n",
      "Epoch 00009: val_loss did not improve from 1.88361\n",
      "167/167 [==============================] - 113s 678ms/step - loss: 0.4949 - accuracy: 0.8432 - val_loss: 2.5854 - val_accuracy: 0.5313\n",
      "Epoch 10/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.4350 - accuracy: 0.8625\n",
      "Epoch 00010: val_loss did not improve from 1.88361\n",
      "167/167 [==============================] - 113s 678ms/step - loss: 0.4353 - accuracy: 0.8622 - val_loss: 6.0565 - val_accuracy: 0.3333\n",
      "Epoch 11/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8814\n",
      "Epoch 00011: val_loss did not improve from 1.88361\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "167/167 [==============================] - 113s 678ms/step - loss: 0.3867 - accuracy: 0.8814 - val_loss: 2.2930 - val_accuracy: 0.5347\n",
      "Epoch 12/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.1696 - accuracy: 0.9431\n",
      "Epoch 00012: val_loss improved from 1.88361 to 1.67243, saving model to googlenet_model/GOOGLENET-Sigmoid-012-0.9432-1.6724.hdf5\n",
      "167/167 [==============================] - 115s 691ms/step - loss: 0.1694 - accuracy: 0.9432 - val_loss: 1.6724 - val_accuracy: 0.6802\n",
      "Epoch 13/50\n",
      "166/167 [============================>.] - ETA: 1s - loss: 0.0878 - accuracy: 0.9717 - ETA: 13s -  - ETA: 0s - loss: 0.0876 - accuracy: 0.9718\n",
      "Epoch 00013: val_loss did not improve from 1.67243\n",
      "167/167 [==============================] - 115s 689ms/step - loss: 0.0876 - accuracy: 0.9718 - val_loss: 1.9319 - val_accuracy: 0.6447\n",
      "Epoch 14/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0749 - accuracy: 0.9743\n",
      "Epoch 00014: val_loss did not improve from 1.67243\n",
      "167/167 [==============================] - 114s 682ms/step - loss: 0.0749 - accuracy: 0.9742 - val_loss: 1.7086 - val_accuracy: 0.6768\n",
      "Epoch 15/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0621 - accuracy: 0.9783\n",
      "Epoch 00015: val_loss did not improve from 1.67243\n",
      "167/167 [==============================] - 114s 680ms/step - loss: 0.0625 - accuracy: 0.9782 - val_loss: 2.0952 - val_accuracy: 0.6819\n",
      "Epoch 16/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0810 - accuracy: 0.9733\n",
      "Epoch 00016: val_loss did not improve from 1.67243\n",
      "167/167 [==============================] - 113s 675ms/step - loss: 0.0807 - accuracy: 0.9733 - val_loss: 1.8901 - val_accuracy: 0.6819\n",
      "Epoch 17/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0747 - accuracy: 0.9773\n",
      "Epoch 00017: val_loss did not improve from 1.67243\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "167/167 [==============================] - 113s 678ms/step - loss: 0.0752 - accuracy: 0.9771 - val_loss: 2.0457 - val_accuracy: 0.6633\n",
      "Epoch 18/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0435 - accuracy: 0.9866\n",
      "Epoch 00018: val_loss did not improve from 1.67243\n",
      "167/167 [==============================] - 113s 679ms/step - loss: 0.0433 - accuracy: 0.9867 - val_loss: 1.7744 - val_accuracy: 0.7022\n",
      "Epoch 19/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.9887- ETA: 8s - loss: 0\n",
      "Epoch 00019: val_loss did not improve from 1.67243\n",
      "167/167 [==============================] - 114s 681ms/step - loss: 0.0345 - accuracy: 0.9887 - val_loss: 1.9012 - val_accuracy: 0.7124\n",
      "Epoch 20/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0231 - accuracy: 0.9932\n",
      "Epoch 00020: val_loss did not improve from 1.67243\n",
      "167/167 [==============================] - 113s 679ms/step - loss: 0.0230 - accuracy: 0.9932 - val_loss: 1.7661 - val_accuracy: 0.7090\n",
      "Epoch 21/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9949\n",
      "Epoch 00021: val_loss did not improve from 1.67243\n",
      "167/167 [==============================] - 113s 679ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 1.7516 - val_accuracy: 0.7259\n",
      "Epoch 22/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9941\n",
      "Epoch 00022: val_loss did not improve from 1.67243\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
      "167/167 [==============================] - 113s 677ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 1.8102 - val_accuracy: 0.7225\n",
      "Epoch 23/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9972\n",
      "Epoch 00023: val_loss did not improve from 1.67243\n",
      "167/167 [==============================] - 113s 676ms/step - loss: 0.0149 - accuracy: 0.9970 - val_loss: 1.8483 - val_accuracy: 0.7090\n",
      "Epoch 24/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9957\n",
      "Epoch 00024: val_loss did not improve from 1.67243\n",
      "167/167 [==============================] - 113s 678ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 1.7241 - val_accuracy: 0.7377\n",
      "Epoch 25/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9972\n",
      "Epoch 00025: val_loss did not improve from 1.67243\n",
      "167/167 [==============================] - 113s 676ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 1.7630 - val_accuracy: 0.7259\n",
      "Epoch 26/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9974\n",
      "Epoch 00026: val_loss did not improve from 1.67243\n",
      "167/167 [==============================] - 113s 676ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 1.7152 - val_accuracy: 0.7191\n",
      "Epoch 27/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9975\n",
      "Epoch 00027: val_loss did not improve from 1.67243\n",
      "167/167 [==============================] - 113s 679ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 1.7460 - val_accuracy: 0.7343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9974\n",
      "Epoch 00028: val_loss did not improve from 1.67243\n",
      "167/167 [==============================] - 113s 677ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 1.8968 - val_accuracy: 0.7377\n",
      "Epoch 29/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9972\n",
      "Epoch 00029: val_loss did not improve from 1.67243\n",
      "167/167 [==============================] - 114s 680ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 1.7844 - val_accuracy: 0.7411\n",
      "Epoch 30/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9975\n",
      "Epoch 00030: val_loss did not improve from 1.67243\n",
      "167/167 [==============================] - 114s 681ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 1.9309 - val_accuracy: 0.7208\n",
      "Epoch 31/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9958\n",
      "Epoch 00031: val_loss did not improve from 1.67243\n",
      "167/167 [==============================] - 113s 679ms/step - loss: 0.0157 - accuracy: 0.9959 - val_loss: 1.9050 - val_accuracy: 0.7225\n",
      "Epoch 32/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9975\n",
      "Epoch 00032: val_loss did not improve from 1.67243\n",
      "167/167 [==============================] - 113s 678ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 1.9739 - val_accuracy: 0.7225\n",
      "Epoch 33/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9966\n",
      "Epoch 00033: val_loss did not improve from 1.67243\n",
      "167/167 [==============================] - 114s 680ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 1.8906 - val_accuracy: 0.7242\n",
      "Epoch 34/50\n",
      "  1/167 [..............................] - ETA: 3:26:36"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\gpumachine\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[1;34m(self, epoch, mode)\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m       \u001b[1;32myield\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gpumachine\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gpumachine\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gpumachine\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gpumachine\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gpumachine\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gpumachine\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gpumachine\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gpumachine\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gpumachine\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gpumachine\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-cbdf54688ed8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVALID_GENERATOR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCALLBACK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;32m~\\.conda\\envs\\gpumachine\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\gpumachine\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    370\u001b[0m                       total_epochs=1)\n\u001b[0;32m    371\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m--> 372\u001b[1;33m                                  prefix='val_')\n\u001b[0m\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gpumachine\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gpumachine\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[1;34m(self, epoch, mode)\u001b[0m\n\u001b[0;32m    683\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[1;31m# Epochs only apply to `fit`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gpumachine\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gpumachine\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    963\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 965\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_worker_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[1;31m# For multi-worker training, back up the weights and current training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gpumachine\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    982\u001b[0m                   int) or self.epochs_since_last_save >= self.period:\n\u001b[0;32m    983\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs_since_last_save\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 984\u001b[1;33m       \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_file_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_best_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\gpumachine\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_get_file_path\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     if not multi_worker_util.in_multi_worker_mode(\n\u001b[0;32m   1019\u001b[0m     ) or multi_worker_util.should_save_checkpoint():\n\u001b[1;32m-> 1020\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1021\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m       \u001b[1;31m# If this is multi-worker training, and this worker should not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(TRAIN_GENERATOR,\n",
    "                    epochs=50,\n",
    "                    validation_data=VALID_GENERATOR,\n",
    "                    callbacks=CALLBACK,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wrong-timeline",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-fef0560d2821>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 손실 그래프\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training Loss vs Validation Loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epochs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# 손실 그래프\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Training Loss vs Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 그래프\n",
    "plt.plot([x * 100 for x in history.history['accuracy']])\n",
    "plt.plot([x * 100 for x in history.history['val_accuracy']])\n",
    "plt.title('Training Accuracy vs Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최신 체크포인트 파일 찾기\n",
    "checkpoint_files = glob.glob('googlenet_model/*.hdf5')\n",
    "latest_checkpoint = max(checkpoint_files, key=os.path.getctime)\n",
    "\n",
    "# 모델에 최신 가중치 로드\n",
    "model.load_weights(latest_checkpoint)\n",
    "\n",
    "# Validation 데이터에 대한 정확도 확인\n",
    "val_loss, val_accuracy = model.evaluate(VALID_GENERATOR)\n",
    "print('Validation Loss:', round(val_loss, 6))\n",
    "print('Validation Accuracy:', round(val_accuracy, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "TEST_GENERATOR = DATAGEN_TRAIN.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='img_path',\n",
    "    y_col='id',\n",
    "    target_size=(244, 244),\n",
    "    class_mode='raw',\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "TEST_GENERATOR.reset()\n",
    "\n",
    "# 최신 체크포인트 파일 찾기\n",
    "checkpoint_files = glob.glob('googlenet_model/*.hdf5')\n",
    "latest_checkpoint = max(checkpoint_files, key=os.path.getctime)\n",
    "\n",
    "print(latest_checkpoint)\n",
    "\n",
    "# 모델에 최신 가중치 로드\n",
    "model.load_weights(latest_checkpoint)\n",
    "\n",
    "test_prediction = model.predict(TEST_GENERATOR, verbose=1)\n",
    "display(test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = np.argmax(test_prediction, axis = 1)\n",
    "test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction_df = pd.DataFrame(test_prediction, columns = ['artist'])\n",
    "test_prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "artist_df = train_df.copy()\n",
    "artist_le = label_encoder.fit_transform(artist_df['artist'].values)\n",
    "artist_df['num'] = artist_le\n",
    "artist_df = artist_df.drop('id', axis=1)\n",
    "artist_df = artist_df.drop('img_path', axis=1)\n",
    "test_prediction_dic = test_prediction_df.to_dict()\n",
    "test_prediction_values = test_prediction_dic['artist'].values()\n",
    "test_prediction_list = list(test_prediction_values)\n",
    "artist_df.set_index('num', inplace=True)\n",
    "artist_df = artist_df.sort_index()\n",
    "artist_info_dic = artist_df['artist'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_name = []\n",
    "for i in test_prediction_list:\n",
    "    artist_name.append(artist_info_dic[i])\n",
    "artist_name[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(\"./sample_submission.csv\")\n",
    "submission_df = submission_df.drop('artist', axis=1)\n",
    "submission_df['artist'] = artist_name\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"googlenet_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-powder",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
